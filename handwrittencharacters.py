# -*- coding: utf-8 -*-
"""HandwrittenCharacters.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1to_hFO4RPeRss7qFIV9KogY7M7HQtUUA
"""

from google.colab import files
uploaded = files.upload()

import zipfile
import os

# Define the path to the uploaded ZIP file and the extraction directory
zip_path = 'Validation.zip'
extract_path = '/content/Validation'

# Create the extraction directory if it doesn't exist
if not os.path.exists(extract_path):
    os.makedirs(extract_path)

# Extract the ZIP file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

base_dir = '/content/Validation'

# List subdirectories in the base directory
for subdir, dirs, files in os.walk(base_dir):
    if dirs:
        print(f"Subdirectories in {subdir}: {dirs}")
    if files:
        print(f"Files in {subdir}: {files}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Correct directory structure
train_dir = '/content/Validation/Validation'  # Adjust if necessary

datagen = ImageDataGenerator(
    rescale=1./255,            # Normalize pixel values to [0, 1]
    validation_split=0.2       # Split data into training and validation sets
)

# Reload data
train_data = datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

validation_data = datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# Check number of classes and class labels
print(f"Number of classes: {len(train_data.class_indices)}")
print(f"Class labels: {train_data.class_indices}")

import tensorflow as tf

# Check if GPU is available
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Define the CNN model
with tf.device('/GPU:0'):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
        MaxPooling2D(pool_size=(2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dense(39, activation='softmax')  # 39 classes
    ])

    # Compile the model
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

# Train the model
with tf.device('/GPU:0'):
    history = model.fit(
        train_data,
        validation_data=validation_data,
        epochs=10
    )

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'])
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'])
plt.show()

pip install python-telegram-bot

import telegram
print(telegram.__version__)

from telegram.ext import filters

!pip install nest_asyncio

import nest_asyncio
nest_asyncio.apply()

from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackContext, filters
import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model

nest_asyncio.apply()

# Define path for the temporary image
IMAGE_PATH = '/content/temp_image.jpg'

# Load and preprocess the image
def load_and_preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(150, 150))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0
    return img_array

# Define command handler for /start
async def start(update: Update, context: CallbackContext):
    await update.message.reply_text('Send me a photo of handwritten text and I will recognize it.')

# Define message handler for photo messages
async def handle_photo(update: Update, context: CallbackContext):
    # Download the photo
    photo_file = await update.message.photo[-1].get_file()
    await photo_file.download_to_drive(IMAGE_PATH)

    # Load and preprocess the image
    img_array = load_and_preprocess_image(IMAGE_PATH)

    # Predict the class
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions, axis=1)

    # Map predicted class index to class label
    class_labels = {v: k for k, v in train_data.class_indices.items()}
    predicted_label = class_labels.get(predicted_class[0], "Unknown")

    await update.message.reply_text(f"Recognized Text: {predicted_label}")

# Main function to start the bot
async def main():
    # Create the Application and pass it your bot's token
    application = Application.builder().token("Replace_with_your_token").build()  # Replace with your token

    # Add handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))

    # Start polling
    await application.run_polling()

if __name__ == '__main__':
    import asyncio
    asyncio.run(main())